spring:
  application:
    name: spring-AI
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4o-mini
#          max-tokens: 100 #max number of tokens in the response
#          temperature: 0.7 #control creativity -> 0: focused - 1: random
#      embedding:
#        options:
#          model: text-embedding-3-small
    ollama:
      chat:
        options:
          model: llama3.2:1b
    chat:
      client:
        enabled: false
      memory:
        repository:
          jdbc:
            initialize-schema: always
            schema: classpath:/schema/schema-h2db.sql
    vectorstore:
      qdrant:
        initialize-schema: true
        host: localhost
        port: 6334 #spring AI framework is going to use the gRPC protocol to communicate with vector database
        collection-name: tom
  main:
    banner-mode: off
  datasource:
    url: jdbc:h2:file:./data/spring-AI-database;AUTO_SERVER=true
    driver-class-name: org.h2.Driver
    username: khanh
    password: 12345
  jpa:
    hibernate:
      ddl-auto: update #update the schema if necessary
  h2:
    console:
      enabled: true
  docker:
    compose:
      enabled: true
      file: docker-compose.yml
      stop:
        command: down #whenever stop the application -> container will be completely deleted

server:
  port: 8080

logging:
  pattern:
    console: "%green(%d{yyyy-MM-dd HH:mm:ss.SSS}) %blue(%-5level) %magenta(${PID:- }) --- %red([%15.15thread]) %yellow(%-40.40logger{39}): %msg%n%wEx"
  level:
    org.tommap.springai: debug
    org.springframework.ai.chat.client.advisor: debug

tavily:
  api-key: ${TAVILY_API_KEY}
  search-base-url: ${TAVILY_SEARCH_BASE_URL}
  max-results: 5